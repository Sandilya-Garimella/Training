{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TREES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision tree:\n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "It is a tree where each node represents a feature(attribute) and each link(branch) represents a decision tree(rule) and each leaf represents an outcome."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algorithms to construct decision trees:\n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1) CART\n",
    "2) ID3"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "CART stands for Classification and regression trees. \n",
    "CART uses Gini index/impurity to construct the tree.\n",
    "Sci-kit uses CART algorithm to construct trees."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ID3 stands for Iterative Dichotomiser 3.\n",
    "This algorithm creates a tree using the entropy function and the categorical feature with highest entropy is taken as the node."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Any of these can be used to construct trees based on our requirement.\n",
    "Gini index is much faster but, the results that we obtain using entropy function are slightly better."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Nowadays, CART is widely used since is simple to interpret and faster.\n",
    "Also it can handle both Categorical as well as numerical data.\n",
    "Finally, there will be very low effort from our side during the data preparation."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Disadvantages of Trees:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1) Unfortunately, trees generally do not have the same level of predictive accuracy as some of the other regression and classification approaches.\n",
    "\n",
    "2) Additionally, trees can be very non-robust. In other words, a small change in the data can cause a large change in the final estimated tree. \n",
    "That is a small variation in data might result in a completely different tree.(variation)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Applications of Trees:\n",
    "    1)It can predict if a customer can pay his renewal premium with an insurance company. [Yes/No](Classification)\n",
    "    2)Determine if a person is Male or Female taking into consideration their height, weight and age.\n",
    "    3)Determine the cost of a house based on the number of rooms and the floor size.\n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Due to the above disadvantages of trees, new methods such as bagging and boosting were proposed to lower the variance of the trees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble learning:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Ensemble is when we combine multiple models. \n",
    "Ensemble methods are of two types:\n",
    "    1) Bagging\n",
    "    2) Boosting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Bagging is also known as Bootstrap aggregation. \n",
    "In bagging/bootstrap aggregation, we take multiple base learners and feed data from our main data to those base learners. The data that is fed to those base learners is by either row sampling with replacement or feature sampling with replacement.\n",
    "So, here bootstrap is row sampling or feature sampling with replacement step.\n",
    "Aggregation is combining the results from those base learners to get a single output.`\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "For a given x,  fˆ1(x), fˆ2(x),... , fˆB (x) are B models based on separate training sets. Then the of average them in order to obtain a single low-variance statistical learning model,\n",
    "\n",
    "          T\n",
    "   f(x)=  ∑ fi(x)\n",
    "          i=1\n",
    "\n",
    "In case of classification, we take the majority vote."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Random forest is a classic example of bagging/bootstrap aggregation\n",
    "In random forest, base learner is decision tree."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Disadvantage of bagging:\n",
    "    When there is one very strong predictor in the data set, along with a number of other moderately strong predictors. Then in the collection of bagged trees, most or all of the trees will use this strong predictor in the top split. Consequently, all of the bagged trees will look quite similar to each other.\n",
    "\n",
    "Hence the predictions from the bagged trees will be highly correlated. Unfortunately, averaging many highly correlated quantities does not lead to as large of a reduction in variance as averaging many uncorrelated quantities.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boosting:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Boosting works in a similar way to bagging but in the case of boosting, trees are grown sequentially i.e each tree is grown using information from previously grown trees.\n",
    "Boosting does not involve bootstrap sampling; instead each tree is fit on a modified version of the original data set and learns slowly from the fitted model for the next"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Boosting has 3 tuning parameters:\n",
    "    1) Unlike bagging, boosting can overfit if \"B\" is too large.\n",
    "       Here \"B\" is the number of trees. To select the value of B, we use cross validation.\n",
    "    2) Shrinkage paramter (or) tuning paramter (λ)\n",
    "       This controls the learning rate of the tree.\n",
    "       Generally λ value is taken as either 0.01 or 0.001.\n",
    "    3) The number of splits in each tree(D)\n",
    "       D controls complexity of the boosted ensemble.\n",
    "       For good results, D is generally taken as 1.\n",
    "       When d=1 there is a single split. This single split tree is called a stump.\n",
    "       "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "If we take the tuning parameter value low such as 0.01, B(number of trees) has to be very high for good performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BAGGING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import model_selection \n",
    "from sklearn.ensemble import BaggingClassifier \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Using the Adult dataset from UCI repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"D:\\Users\\sandilya_garimella\\Documents\\Sandilya\\DataSets\\Adult_full.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass  fnlwgt   education  education-num  \\\n",
       "0   39          State-gov   77516   Bachelors             13   \n",
       "1   50   Self-emp-not-inc   83311   Bachelors             13   \n",
       "2   38            Private  215646     HS-grad              9   \n",
       "3   53            Private  234721        11th              7   \n",
       "4   28            Private  338409   Bachelors             13   \n",
       "\n",
       "        marital-status          occupation    relationship    race      sex  \\\n",
       "0        Never-married        Adm-clerical   Not-in-family   White     Male   \n",
       "1   Married-civ-spouse     Exec-managerial         Husband   White     Male   \n",
       "2             Divorced   Handlers-cleaners   Not-in-family   White     Male   \n",
       "3   Married-civ-spouse   Handlers-cleaners         Husband   Black     Male   \n",
       "4   Married-civ-spouse      Prof-specialty            Wife   Black   Female   \n",
       "\n",
       "   capital-gain  capital-loss  hours-per-week  native-country  income  \n",
       "0          2174             0              40   United-States   <=50K  \n",
       "1             0             0              13   United-States   <=50K  \n",
       "2             0             0              40   United-States   <=50K  \n",
       "3             0             0              40   United-States   <=50K  \n",
       "4             0             0              40            Cuba   <=50K  "
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'workclass', 'fnlwgt', 'education', 'education-num',\n",
       "       'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
       "       'capital-gain', 'capital-loss', 'hours-per-week', 'native-country',\n",
       "       'income'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "le=LabelEncoder()\n",
    "for i,v in enumerate(['workclass','education','marital-status','race','occupation', 'relationship', 'sex','native-country']):\n",
    "\n",
    "    df.loc[:,v]=le.fit_transform(df.loc[:,v])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating numpy arrays for features and target\n",
    "X= df.drop('income',axis=1)\n",
    "y= df['income']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bagging classifier \n",
    "clf_bg = BaggingClassifier(base_estimator = DecisionTreeClassifier(),n_estimators = 10, random_state = 8) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy :\n",
      "84.70565665031431\n"
     ]
    }
   ],
   "source": [
    "results_bg = model_selection.cross_val_score(clf_bg, X, y, cv = 10) #lower cv value is taken to decrease the execution time.\n",
    "print(\"accuracy :\") \n",
    "print(results_bg.mean()*100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RANDOM FOREST:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_rf = RandomForestClassifier(n_estimators=10, max_depth=None, min_samples_split=2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84.9206264488733"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_rf = cross_val_score(clf_rf, X, y, cv=10)\n",
    "scores_rf.mean()*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BOOSTING:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ADABOOST:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86.5974712186717"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_ab = AdaBoostClassifier(n_estimators=100)\n",
    "scores = cross_val_score(clf_ab, X, y, cv=10)\n",
    "scores.mean()*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRADIENT BOOSTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy :\n",
      "86.48999433463665\n"
     ]
    }
   ],
   "source": [
    "clf_gb = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0).fit(X,y)\n",
    "results_gb = model_selection.cross_val_score(clf_gb, X, y, cv = 10) \n",
    "print(\"accuracy :\") \n",
    "print(results_gb.mean()*100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ENSEMBLED METHODS COMPARISION:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 84.71 (+/- 0.00) [BAGGING CLASSIFIER]\n",
      "Accuracy: 84.92 (+/- 0.00) [RandomForest]\n",
      "Accuracy: 86.60 (+/- 0.01) [AdaBoost]\n",
      "Accuracy: 86.49 (+/- 0.01) [GradientBoosting]\n"
     ]
    }
   ],
   "source": [
    "for clf, label in zip([clf_bg, clf_rf,clf_ab, clf_gb], ['BAGGING CLASSIFIER','RandomForest','AdaBoost', 'GradientBoosting']):\n",
    "         scores = cross_val_score(clf, X, y, scoring='accuracy', cv=10)\n",
    "         print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean()*100, scores.std(), label))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Clearly AdaBoost gives us the highest accuracy score.\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "References:\n",
    "1) Introduction to Statistical Learning by Robert Tibshirani\n",
    "2) Machine Learning An algorithmic perspective by Stephen Marshland\n",
    "2) Sklearn relevant resources\n",
    "3) Wikipedia relevant resources\n",
    "4) Kaggle relevant resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
